{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2089458e",
   "metadata": {},
   "source": [
    "# Weather forecasting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cbec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/bids_weather_forecasting_hackathon/track2/makani/makani/mpu/layers.py:174: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, X, weight, bias, inp_group_name, out_group_name):\n",
      "/bids_weather_forecasting_hackathon/track2/makani/makani/mpu/layers.py:196: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_out):\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from functools import partial\n",
    "\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "from era5.dataloader_era5 import *\n",
    "from models.utils import pop_prefix_from_state_dict\n",
    "\n",
    "from aurora import Aurora, rollout\n",
    "from aurora import Batch, Metadata\n",
    "\n",
    "from makani.models.networks.sfnonet import SphericalFourierNeuralOperatorNet as SFNO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8035e748",
   "metadata": {},
   "source": [
    "# Data setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e4f0f",
   "metadata": {},
   "source": [
    "We created a dataloader for loading the ERA5 input data. Each weather forecasting model we include in our setup here is trained on ERA5 data, but needs to have a specific input format. The dataloader loads the data and provides it, depending on which model is used, in the correct format. The dataloader has to be initialized at the beginning, and then you can pick a date and a model, and it outputs the corresponding data at that time in the correct format. Use the ```get_data``` method for this. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac073b0",
   "metadata": {},
   "source": [
    "We've created a custom dataloader to streamline the process of preparing ERA5 input data for our weather forecasting models.\n",
    "\n",
    "### How It Works\n",
    "This dataloader is designed to handle the specific input format requirements of each model in our setup. Instead of manually reformatting the data for every model, you simply initialize the dataloader once at the start of your program.\n",
    "\n",
    "After initialization, you can use the ```get_data``` method. This method takes two arguments: a date and the specific model you wish to use. The dataloader then automatically fetches the corresponding ERA5 data and delivers it in the correct format for that particular model. This ensures a consistent and efficient data pipeline for the included models. You might want to extend the functionality of the dataloader to other model's requirements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a6f8206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats for now\n",
    "metadata_path = \"/era5/2018/73varQ/data.json\"\n",
    "data_path = \"/era5/2018/73varQ/restricted_3days_2018.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792a61e6",
   "metadata": {},
   "source": [
    "# AURORA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f668b374",
   "metadata": {},
   "source": [
    "This is an example code of how to run inference for the pretrained AURORA model.\n",
    "\n",
    "- [Paper Link](https://www.nature.com/articles/s41586-025-09005-y)\n",
    "- [Github Link](https://github.com/microsoft/aurora/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dc7e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataloader_era5(\n",
    "    data_path=data_path,\n",
    "    metadata_path=metadata_path,\n",
    "    in_channels=None,\n",
    "    out_channels=None,\n",
    "    model='aurora',\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d33f8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "aurora_model = Aurora(use_lora=False)  # The pretrained version does not use LoRA.\n",
    "aurora_model.load_checkpoint(\"microsoft/aurora\", \"aurora-0.25-pretrained.ckpt\")\n",
    "\n",
    "aurora_model.eval()\n",
    "aurora_model = aurora_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1877bfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2018-01-02 06:00:00+00:00\n",
      "Reading input file from /era5/2018/73varQ/restricted_3days_2018.h5...\n",
      "Shape of data_handle: (13, 75, 721, 1440)\n",
      "Shape of data: torch.Size([2, 75, 721, 1440])\n",
      "Channel list: ['u10m', 'v10m', 'u100m', 'v100m', 't2m', 'sp', 'msl', 'tcwv', 'u50', 'u100', 'u150', 'u200', 'u250', 'u300', 'u400', 'u500', 'u600', 'u700', 'u850', 'u925', 'u1000', 'v50', 'v100', 'v150', 'v200', 'v250', 'v300', 'v400', 'v500', 'v600', 'v700', 'v850', 'v925', 'v1000', 'z50', 'z100', 'z150', 'z200', 'z250', 'z300', 'z400', 'z500', 'z600', 'z700', 'z850', 'z925', 'z1000', 't50', 't100', 't150', 't200', 't250', 't300', 't400', 't500', 't600', 't700', 't850', 't925', 't1000', 'q50', 'q100', 'q150', 'q200', 'q250', 'q300', 'q400', 'q500', 'q600', 'q700', 'q850', 'q925', 'q1000', 'sst', 'tp']\n",
      "Shape of static variables: torch.Size([3, 721, 1440])\n",
      "Shape of data: torch.Size([2, 75, 721, 1440])\n",
      "Time: 2018-01-02 06:00:00\n"
     ]
    }
   ],
   "source": [
    "date = \"2018-01-02T06:00:00\"\n",
    "batch = dataloader.get_data(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef240307",
   "metadata": {},
   "outputs": [],
   "source": [
    "aurora_model.eval()\n",
    "aurora_model = aurora_model.to(\"cpu\")\n",
    "batch = batch.to(\"cpu\")\n",
    "\n",
    "with torch.inference_mode():\n",
    "    preds = [pred.to(\"cpu\") for pred in rollout(aurora_model, batch, steps=1)]\n",
    "    aurora_model = aurora_model.to(\"cpu\")\n",
    "\n",
    "print(f\"Preds: {preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf9e8f5",
   "metadata": {},
   "source": [
    "# PANGU-WEATHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8133caa0",
   "metadata": {},
   "source": [
    "This is an example code of how to run inference for the pretrained Pangu-Weather model.\n",
    "\n",
    "- [Paper Link](https://www.nature.com/articles/s41586-023-06185-3)\n",
    "- [Github Link](https://github.com/198808xc/Pangu-Weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e93971",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = dataloader_era5(\n",
    "    data_path=data_path,\n",
    "    metadata_path=metadata_path,\n",
    "    in_channels=None,\n",
    "    out_channels=None,\n",
    "    model='pangu',\n",
    "    normalize=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84aa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pangu_model_sess = models.pangu.define_pangu_onnx(model_type=6)\\nprint(f\"Pangu model {pangu_model_sess}\")'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pangu_model_sess = models.pangu.define_pangu_onnx(model_type=6)\n",
    "print(f\"Pangu model {pangu_model_sess}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7cc2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2018-01-02 06:00:00+00:00\n",
      "Reading input file from /era5/2018/73varQ/restricted_3days_2018.h5...\n",
      "Shape of data_handle: (13, 75, 721, 1440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (75, 721, 1440)\n",
      "Channel list: ['u10m', 'v10m', 'u100m', 'v100m', 't2m', 'sp', 'msl', 'tcwv', 'u50', 'u100', 'u150', 'u200', 'u250', 'u300', 'u400', 'u500', 'u600', 'u700', 'u850', 'u925', 'u1000', 'v50', 'v100', 'v150', 'v200', 'v250', 'v300', 'v400', 'v500', 'v600', 'v700', 'v850', 'v925', 'v1000', 'z50', 'z100', 'z150', 'z200', 'z250', 'z300', 'z400', 'z500', 'z600', 'z700', 'z850', 'z925', 'z1000', 't50', 't100', 't150', 't200', 't250', 't300', 't400', 't500', 't600', 't700', 't850', 't925', 't1000', 'q50', 'q100', 'q150', 'q200', 'q250', 'q300', 'q400', 'q500', 'q600', 'q700', 'q850', 'q925', 'q1000', 'sst', 'tp']\n",
      "Shape of upper data: (5, 13, 721, 1440)\n",
      "Shape of surface data: (4, 721, 1440)\n"
     ]
    }
   ],
   "source": [
    "date = \"2018-01-02T06:00:00\"\n",
    "upper_data, surface_data = dataloader.get_data(date)\n",
    "print(f\"Shape of upper data: {upper_data.shape}\")\n",
    "print(f\"Shape of surface data: {surface_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ff02dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Run the inference session\\noutput_upper, output_surface = pangu_model_sess.run(None, {\\'input\\':upper_data, \\'input_surface\\':surface_data})\\nprint(f\"Shape of output_upper: {output_upper.shape}\")\\nprint(f\"Shape of output_surface: {output_surface.shape}\")'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the inference session\n",
    "output_upper, output_surface = pangu_model_sess.run(None, {'input':upper_data, 'input_surface':surface_data})\n",
    "print(f\"Shape of output_upper: {output_upper.shape}\")\n",
    "print(f\"Shape of output_surface: {output_surface.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64832af7",
   "metadata": {},
   "source": [
    "# SFNO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb748d3a",
   "metadata": {},
   "source": [
    "This is an example code of how to run inference for the pretrained SFNO model.\n",
    "\n",
    "- [Paper Link](https://arxiv.org/abs/2306.03838)\n",
    "- [Github Link](https://github.com/NVIDIA/makani/tree/v0.1.1)\n",
    "\n",
    "The model weights were taken from the public NVIDIA Modulus release [here](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/modulus/models/sfno_73ch_small). Note that this is not the final model, but a smaller version of the SFNO model. Please download the data, the dataloader now assumes it is located under ```/era5/sfno```.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ac986c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic stats for now\n",
    "metadata_path = \"/era5/2018/73varQ/data.json\"\n",
    "data_path = \"/era5/2018/73varQ/restricted_1stday_jan_2018.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44182ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded stats for the SFNO model.\n",
      "Shape of mean: (1, 75, 1, 1)\n",
      "Shape of std: (1, 75, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "dataloader = dataloader_era5(\n",
    "    data_path=data_path,\n",
    "    metadata_path=metadata_path,\n",
    "    in_channels=None,\n",
    "    out_channels=None,\n",
    "    model='sfno',\n",
    "    normalize=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72752bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2018-01-01 06:00:00+00:00\n",
      "Reading input file from /era5/2018/73varQ/restricted_1stday_jan_2018.h5...\n",
      "Shape of data_handle: (5, 75, 721, 1440)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (75, 721, 1440)\n",
      "Channel list: ['u10m', 'v10m', 'u100m', 'v100m', 't2m', 'sp', 'msl', 'tcwv', 'u50', 'u100', 'u150', 'u200', 'u250', 'u300', 'u400', 'u500', 'u600', 'u700', 'u850', 'u925', 'u1000', 'v50', 'v100', 'v150', 'v200', 'v250', 'v300', 'v400', 'v500', 'v600', 'v700', 'v850', 'v925', 'v1000', 'z50', 'z100', 'z150', 'z200', 'z250', 'z300', 'z400', 'z500', 'z600', 'z700', 'z850', 'z925', 'z1000', 't50', 't100', 't150', 't200', 't250', 't300', 't400', 't500', 't600', 't700', 't850', 't925', 't1000', 'q50', 'q100', 'q150', 'q200', 'q250', 'q300', 'q400', 'q500', 'q600', 'q700', 'q850', 'q925', 'q1000', 'sst', 'tp']\n",
      "Shape of static variables: (1, 4, 721, 1440)\n",
      "Shape of data: (1, 73, 721, 1440)\n",
      "Shape of final data: (1, 77, 721, 1440)\n",
      "Shape of data: torch.Size([1, 77, 721, 1440])\n"
     ]
    }
   ],
   "source": [
    "date = \"2018-01-01T06:00:00\"\n",
    "output_data = dataloader.get_data(date)\n",
    "print(f\"Shape of data: {output_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb6731c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num lat: 721\n",
      "num lon: 1440\n",
      "Num in channels: 77\n",
      "Num out channels: 73\n",
      "Add zenith: True\n",
      "Add landmask: True\n"
     ]
    }
   ],
   "source": [
    "# load config\n",
    "config_path = \"/era5/sfno/sfno_73ch_small_config.json\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "nlat = config['img_shape_x']\n",
    "nlon = config['img_shape_y']\n",
    "print(f\"num lat: {nlat}\")\n",
    "print(f\"num lon: {nlon}\")\n",
    "print(f'Num in channels: {config[\"N_in_channels\"]}')\n",
    "print(f'Num out channels: {config[\"N_out_channels\"]}')\n",
    "print(f'Add zenith: {config[\"add_zenith\"]}')\n",
    "print(f'Add landmask: {config[\"add_landmask\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0311d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = partial(SFNO, \n",
    "    img_size=(nlat, nlon),  \n",
    "    grid=config[\"data_grid_type\"],\n",
    "    num_layers=config['num_layers'], \n",
    "    scale_factor=config['scale_factor'],\n",
    "    inp_chans=config[\"N_in_channels\"],\n",
    "    out_chans=config[\"N_out_channels\"],\n",
    "    embed_dim=config['embed_dim'], \n",
    "    big_skip=True, \n",
    "    pos_embed=config[\"pos_embed\"], \n",
    "    use_mlp=config[\"use_mlp\"], \n",
    "    normalization_layer=config[\"normalization_layer\"]\n",
    ")\n",
    "\n",
    "model = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb6676a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load checkpoint\n",
    "ckpt_path = \"/era5/sfno/checkpoints/sfno_73ch_small_training_checkpoints_best_ckpt_mp0.tar\"\n",
    "checkpoint = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "state_dict = checkpoint[\"model_state\"]\n",
    "pop_prefix_from_state_dict(state_dict, \"module.model.\")\n",
    "model.load_state_dict(state_dict, strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output: torch.Size([1, 73, 721, 1440])\n"
     ]
    }
   ],
   "source": [
    "output_data = torch.tensor(output_data, dtype=torch.float32)\n",
    "pred = model(output_data)\n",
    "print(f\"Shape of output: {pred.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46a541a",
   "metadata": {},
   "source": [
    "# Further readings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f68e09cc",
   "metadata": {},
   "source": [
    "- Benchmark - [WeatherBench](https://sites.research.google/gr/weatherbench/)\n",
    "- IBTrACS - [Cyclone tracking data](https://www.ncei.noaa.gov/products/international-best-track-archive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
